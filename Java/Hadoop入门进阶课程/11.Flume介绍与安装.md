**1	搭建环境**

部署节点操作系统为CentOS，防火墙和SElinux禁用，创建了一个shiyanlou用户并在系统根目录下创建/app目录，用于存放Hadoop等组件运行包。因为该目录用于安装hadoop等组件程序，用户对shiyanlou必须赋予rwx权限（一般做法是root用户在根目录下创建/app目录，并修改该目录拥有者为shiyanlou(chown –R shiyanlou:shiyanlou /app）。

**Hadoop搭建环境：**

- 虚拟机操作系统： CentOS6.6  64位，单核，1G内存
- JDK：1.7.0_55 64位
- Hadoop：1.1.2

**2	Flume介绍**

Flume是Cloudera提供的日志收集系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。 Flume是一个分布式、可靠和高可用的海量日志采集、聚合和传输的系统。

Flume具有Reliability、Scalability、Manageability和Extensibility特点：

1.	Reliability：Flume提供3中数据可靠性选项，包括End-to-end、Store on failure和Best effort。其中End-to-end使用了磁盘日志和接受端Ack的方式，保证Flume接受到的数据会最终到达目的。Store on failure在目的不可用的时候，数据会保持在本地硬盘。和End-to-end不同的是，如果是进程出现问题，Store on failure可能会丢失部分数据。Best effort不做任何QoS保证。 
2.	Scalability：Flume的3大组件：collector、master和storage tier都是可伸缩的。需要注意的是，Flume中对事件的处理不需要带状态，它的Scalability可以很容易实现。 
3.	Manageability：Flume利用ZooKeeper和gossip，保证配置数据的一致性、高可用。同时，多Master，保证Master可以管理大量的节点。 
4.	Extensibility：基于Java，用户可以为Flume添加各种新的功能，如通过继承Source，用户可以实现自己的数据接入方式，实现Sink的子类，用户可以将数据写往特定目标，同时，通过SinkDecorator，用户可以对数据进行一定的预处理。

**2.1	Flume架构**

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433989979142.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)  

上图的Flume的架构中最重要的抽象是data flow（数据流），data flow描述了数据从产生，传输、处理并最终写入目标的一条路径（在上图中，实线描述了data flow）。 Agent用于采集数据，agent是flume中产生数据流的地方，同时，agent会将产生的数据流传输到collector。对应的，collector用于对数据进行聚合，往往会产生一个更大的流。 

Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。同时，Flume的数据接受方，可以是console（控制台）、text（文件）、dfs（HDFS文件）、RPC（Thrift-RPC）和syslogTCP（TCP syslog日志系统）等。 

其中，收集数据有2种主要工作模式，如下： 
1.	Push Sources：外部系统会主动地将数据推送到Flume中，如RPC、syslog。 
2.	Polling Sources：Flume到外部系统中获取数据，一般使用轮询的方式，如text和exec。

注意，在Flume中，agent和collector对应，而source和sink对应。Source和sink强调发送、接受方的特性（如数据格式、编码等），而agent和collector关注功能。

**2.2	Flume管理方式**

Flume Master用于管理数据流的配置，如下图。 
![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990025003.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
  
为了保证可扩展性，Flume采用了多Master的方式。为了保证配置数据的一致性，Flume引入了ZooKeeper，用于保存配置数据，ZooKeeper本身可保证配置数据的一致性和高可用，另外，在配置数据发生变化时，ZooKeeper可以通知Flume Master节点。 
Flume Master间使用gossip协议同步数据。

**3	安装部署Flume**

**3.1	Flume部署过程**

**3.1.1	下载Flume**

可以到apache基金flume官网http://flume.apache.org/download.html，选择镜像下载地址http://mirrors.hust.edu.cn/apache/flume/下载一个稳定版本，如下图所示下载flume-1.5.2-bin.tar.gz：

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990044032.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10) 

也可以在/home/shiyanlou/install-pack目录中找到该安装包，解压该安装包并把该安装包复制到/app目录中
- cd /home/shiyanlou/install-pack
- tar -xzf flume-1.5.2-bin.tar.gz
- mv apache-flume-1.5.2-bin /app/flume-1.5.2

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990067068.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
**3.1.2	设置/etc/profile参数**

编辑/etc/profile文件，声明flume的home路径和在path加入bin的路径：
- export FLUME_HOME=/app/flume-1.5.2
- export FLUME_CONF_DIR=$FLUME_HOME/conf
- export PATH=$PATH:$FLUME_HOME/bin

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990089011.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
编译配置文件/etc/profile，并确认生效
- source /etc/profile
- echo $PATH

**3.1.3	设置flume-env.sh配置文件**

在$FLUME_HOME/conf 下复制改名flume-env.sh.template为flume-env.sh，修改conf/ flume-env.sh配置文件 
- cd /app/flume-1.5.2/conf
- cp flume-env.sh.template flume-env.sh
- sudo vi flume-env.sh

修改配置文件内容 ：
- JAVA_HOME= /app/lib/jdk1.7.0_55
- JAVA_OPTS="-Xms100m -Xmx200m -Dcom.sun.management.jmxremote"

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990109875.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
**3.2	部署验证**

**3.2.1	验证安装**

1.修改flume-conf配置文件
在$FLUME_HOME/conf目录下修改flume-conf.properties.template文件，复制并改名为flume-conf，
- cd /app/flume-1.5.2/conf
- cp flume-conf.properties.template flume-conf.properties
- sudo vi flume-conf.properties

修改flume-conf配置文件内容

```
# The configuration file needs to define the sources, the channels and the sinks.
# Sources, channels and sinks are defined per agent, in this case called 'a1'
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# For each one of the sources, the type is defined
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

#The channel can be defined as follows.
a1.sources.r1.channels = c1
# Each sink's type must be defined
a1.sinks.k1.type = logger

#Specify the channel the sink should use
a1.sinks.k1.channel = c1

# Each channel's type is defined.
a1.channels.c1.type = memory
# Other config values specific to each type of channel(sink or source)
# can be defined as well
# In this case, it specifies the capacity of the memory channel
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990123186.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)

2.在flume的安装目录/flume-1.5.2下运行
- cd /app/flume-1.5.2
- ./bin/flume-ng agent --conf ./conf/ --conf-file - ./conf/flume-conf.properties --name a1 -Dflume.root.logger=INFO,console

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990147798.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
3.再打开一个终端，输入如下命令：
- telnet localhost 44444
- hello world

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990192967.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
注：在CentOS6.5运行telnet提示"command not found"，使用sudo yum install telnet进行安装

4.在原来的终端上查看，可以收到来自于telnet发出的消息
![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990200396.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
**3.2.2	测试收集日志到HDFS**

1.在$FLUME_HOME/conf目录下修改flume-conf.properties.template文件，复制并改名为flume-conf2.properties
- cd /app/flume-1.5.2/conf
- cp flume-conf.properties.template flume-conf2.properties
- sudo vi flume-conf2.properties

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990223625.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
```
a1.sources = r1
a1.sinks = k1
a1.channels = c1
a1.sources.r1.type = exec
a1.sources.r1.channels = c1
a1.sources.r1.command = tail -F /app/hadoop-1.1.2/logs/hadoop-shiyanlou-namenode-b393a04554e1.log
a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
a1.sinks.k1.hdfs.path = hdfs://hadoop:9000/class12/out_flume
a1.sinks.k1.hdfs.filePrefix = events-
a1.sinks.k1.hdfs.round = true
a1.sinks.k1.hdfs.roundValue = 10
a1.sinks.k1.hdfs.roundUnit = minute
a1.sinks.k1.hdfs.rollSize = 4000000
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.writeFormat = Text
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.batchSize = 10
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990236998.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
2.在flume的安装目录/flume-1.5.2下运行
- cd /app/flume-1.5.2
- ./bin/flume-ng agent --conf ./conf/ --conf-file ./conf/flume-conf2.properties --name a1 -Dflume.root.logger=INFO,console

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990251041.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
 
3.不断收集hadoop-hadoop-namenode-hadoop1.log的数据写入HDFS中
![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990261958.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)

4.查看hdfs中/class12/out_flume中的文件
- hadoop fs -ls /class12/out_flume
- hadoop fs -cat /class12/out_flume/events-.1433921305493
 
![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid29778labid1046timestamp1433990269563.png?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)
